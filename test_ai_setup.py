#!/usr/bin/env python3
"""
Test script to verify ThreatForge AI orchestration layer setup
"""

def test_ai_imports():
    """Test if all AI-related modules can be imported"""
    try:
        print("üîç Testing AI module imports...")
        
        # Test AI service
        from app.ai_service import AIOrchestrator, AIAnalysisResult, VulnerabilityAnalysis, MitigationRecommendation
        print("‚úÖ AI service modules imported successfully")
        
        # Test enhanced report generator
        from app.enhanced_report_generator import EnhancedPDFReportGenerator
        print("‚úÖ Enhanced report generator imported successfully")
        
        # Test AI router
        from app.routers.ai import router as ai_router
        print("‚úÖ AI router imported successfully")
        
        # Test LangChain and Groq (optional)
        try:
            from langchain_groq import ChatGroq
            print("‚úÖ LangChain Groq imported successfully")
        except ImportError:
            print("‚ö†Ô∏è  LangChain Groq not available (install with: pip install langchain-groq)")
        
        try:
            import groq
            print("‚úÖ Groq client imported successfully")
        except ImportError:
            print("‚ö†Ô∏è  Groq client not available (install with: pip install groq)")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("üí° Make sure you have installed all AI dependencies:")
        print("   pip install -r requirements.txt")
        return False
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        return False

def test_ai_configuration():
    """Test AI configuration settings"""
    try:
        print("\nüîç Testing AI configuration...")
        
        from app.config import settings
        
        print(f"‚úÖ AI Model Provider: {settings.ai_model_provider}")
        print(f"‚úÖ AI Fallback Enabled: {settings.ai_fallback_enabled}")
        print(f"‚úÖ AI Cost Limit: ${settings.ai_cost_limit_per_job}")
        print(f"‚úÖ AI Model Name: {settings.ai_model_name}")
        print(f"‚úÖ AI Max Tokens: {settings.ai_max_tokens}")
        print(f"‚úÖ AI Temperature: {settings.ai_temperature}")
        
        # Check API keys
        if settings.groq_api_key:
            print(f"‚úÖ Groq API Key: {'Set' if settings.groq_api_key != 'your-groq-api-key-here' else 'Default (configure in .env)'}")
        else:
            print("‚ö†Ô∏è  Groq API Key: Not configured")
        
        if settings.openai_api_key:
            print(f"‚úÖ OpenAI API Key: {'Set' if settings.openai_api_key != 'your-openai-api-key-here' else 'Default (configure in .env)'}")
        else:
            print("‚ö†Ô∏è  OpenAI API Key: Not configured")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Configuration error: {e}")
        return False

def test_ai_orchestrator():
    """Test AI orchestrator functionality"""
    try:
        print("\nüîç Testing AI orchestrator...")
        
        from app.ai_service import AIOrchestrator
        
        # Create orchestrator instance
        orchestrator = AIOrchestrator()
        print("‚úÖ AI orchestrator created successfully")
        
        # Test fallback rules loading
        fallback_rules = orchestrator.fallback_rules
        if fallback_rules and "vulnerability_patterns" in fallback_rules:
            print(f"‚úÖ Fallback rules loaded: {len(fallback_rules['vulnerability_patterns'])} patterns")
        else:
            print("‚ùå Fallback rules not loaded properly")
            return False
        
        # Test available models
        models = orchestrator.get_available_models()
        if models:
            print(f"‚úÖ Available models: {len(models)}")
            for model in models:
                print(f"   - {model['provider']}: {model['name']} ({model['status']})")
        else:
            print("‚ùå No models available")
            return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå AI orchestrator error: {e}")
        return False

def test_enhanced_report_generator():
    """Test enhanced PDF report generator"""
    try:
        print("\nüîç Testing enhanced report generator...")
        
        from app.enhanced_report_generator import EnhancedPDFReportGenerator
        from app.ai_service import AIAnalysisResult, VulnerabilityAnalysis, MitigationRecommendation
        
        # Create report generator
        generator = EnhancedPDFReportGenerator()
        print("‚úÖ Enhanced report generator created successfully")
        
        # Create mock AI analysis result
        mock_vulnerabilities = [
            VulnerabilityAnalysis(
                vulnerability_type="sql_injection",
                description="SQL injection vulnerability detected",
                severity="high",
                cvss_score=8.5,
                affected_components=["login_form", "search_function"],
                attack_vector="network",
                impact="Data compromise",
                likelihood="medium"
            )
        ]
        
        mock_mitigations = [
            MitigationRecommendation(
                priority="high",
                action="Implement parameterized queries",
                description="Use prepared statements to prevent SQL injection",
                implementation_steps=["Review code", "Replace queries", "Test thoroughly"],
                estimated_cost="Low",
                time_to_implement="2-3 days",
                effectiveness="High"
            )
        ]
        
        mock_ai_result = AIAnalysisResult(
            vulnerabilities=mock_vulnerabilities,
            mitigations=mock_mitigations,
            risk_score=75,
            executive_summary="Critical SQL injection vulnerability requires immediate attention",
            technical_details="SQL injection found in login form allowing unauthorized access",
            cost_estimate=0.002,
            model_used="groq_llama3",
            confidence_score=0.85
        )
        
        print("‚úÖ Mock AI analysis result created successfully")
        
        # Test report generation (without actual job object)
        print("‚úÖ Enhanced report generator test completed")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Enhanced report generator error: {e}")
        return False

def test_ai_router():
    """Test AI router endpoints"""
    try:
        print("\nüîç Testing AI router...")
        
        from app.routers.ai import router as ai_router
        
        # Check router configuration
        if ai_router.prefix == "/ai":
            print("‚úÖ AI router prefix configured correctly")
        else:
            print("‚ùå AI router prefix incorrect")
            return False
        
        # Check available endpoints
        routes = [route.path for route in ai_router.routes]
        expected_routes = [
            "/ai/models",
            "/ai/analyze/{job_id}",
            "/ai/status/{job_id}",
            "/ai/costs",
            "/ai/batch-analyze",
            "/ai/health"
        ]
        
        for route in expected_routes:
            if route in routes:
                print(f"‚úÖ Route {route} available")
            else:
                print(f"‚ùå Route {route} missing")
                return False
        
        print("‚úÖ All AI router endpoints available")
        return True
        
    except Exception as e:
        print(f"‚ùå AI router error: {e}")
        return False

def test_cost_optimization():
    """Test AI cost optimization features"""
    try:
        print("\nüîç Testing AI cost optimization...")
        
        from app.ai_service import AIOrchestrator
        
        orchestrator = AIOrchestrator()
        
        # Test cost calculation
        mock_usage = type('MockUsage', (), {
            'prompt_tokens': 1000,
            'completion_tokens': 500
        })()
        
        cost = orchestrator._calculate_cost(mock_usage)
        print(f"‚úÖ Cost calculation: ${cost:.4f} for 1000 input + 500 output tokens")
        
        # Test cost limits
        if cost <= 0.01:
            print("‚úÖ Cost within per-job limit ($0.01)")
        else:
            print("‚ùå Cost exceeds per-job limit")
            return False
        
        return True
        
    except Exception as e:
        print(f"‚ùå Cost optimization error: {e}")
        return False

def main():
    """Run all AI tests"""
    print("üöÄ ThreatForge AI Orchestration Layer Test")
    print("=" * 50)
    
    tests = [
        test_ai_imports,
        test_ai_configuration,
        test_ai_orchestrator,
        test_enhanced_report_generator,
        test_ai_router,
        test_cost_optimization
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
        print()
    
    print("=" * 50)
    print(f"üìä AI Test Results: {passed}/{total} tests passed")
    
    if passed == total:
        print("üéâ All AI tests passed! Your AI orchestration layer is ready.")
        print("\nüöÄ AI Features Available:")
        print("   ‚Ä¢ AI-powered vulnerability analysis")
        print("   ‚Ä¢ Intelligent risk scoring")
        print("   ‚Ä¢ Automated mitigation recommendations")
        print("   ‚Ä¢ Cost-optimized processing")
        print("   ‚Ä¢ Fallback rule-based analysis")
        print("   ‚Ä¢ Enhanced PDF reporting")
        print("\nüìö AI API Endpoints:")
        print("   ‚Ä¢ GET /api/v1/ai/models - Available AI models")
        print("   ‚Ä¢ POST /api/v1/ai/analyze/{job_id} - Request AI analysis")
        print("   ‚Ä¢ GET /api/v1/ai/status/{job_id} - Analysis status")
        print("   ‚Ä¢ GET /api/v1/ai/costs - Cost summary")
        print("   ‚Ä¢ POST /api/v1/ai/batch-analyze - Batch processing")
        print("   ‚Ä¢ GET /api/v1/ai/health - AI service health")
    else:
        print("‚ùå Some AI tests failed. Please check the errors above.")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 